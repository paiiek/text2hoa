# Text2HOA Repository Structure (Cleaned)

**Last updated:** 2025-12-18
**Status:** âœ… Ready for GitHub release

---

## ğŸ“‚ Directory Tree

```
text2hoa/
â”œâ”€â”€ ğŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ğŸ“„ CLEANUP_SUMMARY.md           # Cleanup process details
â”œâ”€â”€ ğŸ“„ STRUCTURE.md                 # This file
â”œâ”€â”€ ğŸ“„ commands.txt                 # Quick reference commands
â”‚
â”œâ”€â”€ ğŸ“ final/                       # ğŸ¯ Production-ready code
â”‚   â”œâ”€â”€ models/                     # (3 files, 1.3GB)
â”‚   â”‚   â”œâ”€â”€ t2sa_e2e_minilm_stage4f_lastmilefocus.pt   # ğŸ† MAIN MODEL (33.2Â° AE)
â”‚   â”‚   â”œâ”€â”€ t2sa_minilm_ft_clean_lastmile_ep6.pt       # Alternative
â”‚   â”‚   â””â”€â”€ t2sa_e2e_e5s_align.pt                      # E5-small variant
â”‚   â”œâ”€â”€ datasets/                   # (6 files, 1.1MB)
â”‚   â”‚   â”œâ”€â”€ text2spatial_v4_train.jsonl
â”‚   â”‚   â”œâ”€â”€ text2spatial_v4_valid.jsonl
â”‚   â”‚   â”œâ”€â”€ text2spatial_v4_test.jsonl
â”‚   â”‚   â”œâ”€â”€ text2spatial_v4_stats.json
â”‚   â”‚   â”œâ”€â”€ text2spatial_v4_qc_report.csv
â”‚   â”‚   â””â”€â”€ tiny.jsonl
â”‚   â””â”€â”€ configs/                    # (10 Python files)
â”‚       â”œâ”€â”€ train_e2e_minilm_v5b_c2f_adamargin_focus_fixed2.py
â”‚       â”œâ”€â”€ train_e2e_e5small_v3_align.py
â”‚       â”œâ”€â”€ train_minimal_v7_stable.py
â”‚       â”œâ”€â”€ eval_lastmile_v4.py
â”‚       â”œâ”€â”€ eval_lastmile_v4cal.py
â”‚       â”œâ”€â”€ eval_lastmile_v3_ori_ì œì¶œìš©.py
â”‚       â”œâ”€â”€ infer_text2spatial_api.py
â”‚       â”œâ”€â”€ infer_render.py
â”‚       â”œâ”€â”€ infer_and_render_utils.py
â”‚       â””â”€â”€ data.py
â”‚
â”œâ”€â”€ ğŸ“ utils/                       # ğŸ”§ Helper scripts (20 files)
â”‚   â”œâ”€â”€ Dataset creation
â”‚   â”‚   â”œâ”€â”€ make_dataset_v3_no_subject.py
â”‚   â”‚   â”œâ”€â”€ augment_text_v3_labelaware.py
â”‚   â”‚   â””â”€â”€ make_ood_textset_v1.py
â”‚   â”œâ”€â”€ Evaluation
â”‚   â”‚   â”œâ”€â”€ eval_ood_textset.py
â”‚   â”‚   â”œâ”€â”€ eval_hrtf_robustness.py
â”‚   â”‚   â”œâ”€â”€ eval_ensemble_calib_v1.py
â”‚   â”‚   â””â”€â”€ eval_model_metrics_simple.py
â”‚   â”œâ”€â”€ Baselines
â”‚   â”‚   â”œâ”€â”€ bakeoff_encoders_v1_fix.py
â”‚   â”‚   â”œâ”€â”€ baseline_rulelex_eval.py
â”‚   â”‚   â””â”€â”€ run_baselines_linear_and_rule.py
â”‚   â”œâ”€â”€ Figures & Tables
â”‚   â”‚   â”œâ”€â”€ gen_fig_ablation.py
â”‚   â”‚   â”œâ”€â”€ gen_fig_coverage.py
â”‚   â”‚   â”œâ”€â”€ gen_fig_ood.py
â”‚   â”‚   â”œâ”€â”€ gen_fig_pipeline.py
â”‚   â”‚   â”œâ”€â”€ make_icassp_tables.py
â”‚   â”‚   â””â”€â”€ csv_to_latex_table.py
â”‚   â””â”€â”€ Analysis
â”‚       â”œâ”€â”€ check_dataset_coverage.py
â”‚       â”œâ”€â”€ quick_stats_v2.py
â”‚       â”œâ”€â”€ analyze_mos.py
â”‚       â””â”€â”€ summarize_eval_logs.py
â”‚
â”œâ”€â”€ ğŸ“ docs/                        # ğŸ“Š Results & documentation
â”‚   â”œâ”€â”€ results/                    # All metrics and tables
â”‚   â”‚   â”œâ”€â”€ metrics_final.json
â”‚   â”‚   â”œâ”€â”€ metrics_all.json
â”‚   â”‚   â”œâ”€â”€ metrics_base.json
â”‚   â”‚   â”œâ”€â”€ ood_metrics.json
â”‚   â”‚   â”œâ”€â”€ baseline_results.csv
â”‚   â”‚   â”œâ”€â”€ icassp_summary_methods.csv
â”‚   â”‚   â”œâ”€â”€ icassp_perbin_all.csv
â”‚   â”‚   â”œâ”€â”€ hrtf_robust_summary.csv
â”‚   â”‚   â””â”€â”€ [15+ more metric files]
â”‚   â”œâ”€â”€ figures/                    # Paper figures (empty, ready for use)
â”‚   â””â”€â”€ make_report_md.py.          # Report generator
â”‚
â”œâ”€â”€ ğŸ“ cache/                       # ğŸ—„ï¸ Pre-computed embeddings (73MB)
â”‚   â”œâ”€â”€ cache_sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2.pt
â”‚   â”œâ”€â”€ cache_intfloat_multilingual-e5-small.pt
â”‚   â”œâ”€â”€ cache_intfloat_multilingual-e5-base.pt
â”‚   â”œâ”€â”€ cache_Alibaba-NLP_gte-multilingual-base.pt
â”‚   â”œâ”€â”€ cache_e5base.pt
â”‚   â””â”€â”€ cache_e5small.pt
â”‚
â”œâ”€â”€ ğŸ“ renderer/                    # ğŸµ Spatial audio rendering (4.9GB)
â”‚   â”œâ”€â”€ hrtf/kemar.sofa
â”‚   â”œâ”€â”€ mos_questions_*/            # MOS test stimuli (multiple instruments)
â”‚   â”œâ”€â”€ demo_out_*/                 # Demo outputs
â”‚   â””â”€â”€ [rendering scripts]
â”‚
â”œâ”€â”€ ğŸ“ v2/                          # ğŸ§ª LoRA experiments (9.4GB)
â”‚   â”œâ”€â”€ icassp_run1/, icassp_run2/
â”‚   â”œâ”€â”€ icassp_run_lora8*/
â”‚   â”œâ”€â”€ config_spatial.json
â”‚   â”œâ”€â”€ train_spatial.py
â”‚   â””â”€â”€ prepare_spatial_dataset.py
â”‚
â”œâ”€â”€ ğŸ“ v3/                          # ğŸ§ª Latest experiments (20MB)
â”‚
â”œâ”€â”€ ğŸ“ emotion/                     # ğŸ˜Š Emotion-based spatial audio (13MB)
â”‚   â”œâ”€â”€ train_weak.jsonl
â”‚   â”œâ”€â”€ prepare_text2spatial.py
â”‚   â””â”€â”€ pro_params_v3.yaml
â”‚
â””â”€â”€ ğŸ“ archive/                     # ğŸ“¦ Historical experiments (~28GB)
    â”œâ”€â”€ intermediate_models/        # Old checkpoints (stages 1-4e, ablations)
    â”œâ”€â”€ intermediate_datasets/      # Dataset variants (parts, augmented versions)
    â”œâ”€â”€ intermediate_scripts/       # Training variants (v1-v6, repair scripts)
    â””â”€â”€ old_eval/                   # Previous evaluation scripts
```

---

## ğŸ“Š Size Breakdown

| Folder | Size | Description |
|--------|------|-------------|
| `final/` | **1.3GB** | Production models + datasets |
| `cache/` | 73MB | Pre-computed embeddings |
| `docs/` | <1MB | Results, metrics, figures |
| `utils/` | <1MB | Helper scripts |
| `renderer/` | 4.9GB | Audio backend + MOS tests |
| `v2/` | 9.4GB | LoRA experiments |
| `v3/` | 20MB | Latest experiments |
| `emotion/` | 13MB | Emotion project |
| `archive/` | **~28GB** | Historical experiments |
| **Total** | **~44GB** | |

---

## ğŸ¯ Quick Access

### **Run Inference**
```bash
cd final/configs
python infer_text2spatial_api.py \
  --ckpt ../models/t2sa_e2e_minilm_stage4f_lastmilefocus.pt \
  --text "ì˜¤ë¥¸ìª½ ì•ì—ì„œ ì²œì²œíˆ ë‹¤ê°€ì™€"
```

### **Evaluate on Test Set**
```bash
cd final/configs
python eval_lastmile_v4.py \
  --data ../datasets/text2spatial_v4_test.jsonl \
  --ckpt ../models/t2sa_e2e_minilm_stage4f_lastmilefocus.pt
```

### **Train New Model**
```bash
cd final/configs
python train_e2e_minilm_v5b_c2f_adamargin_focus_fixed2.py \
  --data ../datasets/text2spatial_v4_train.jsonl \
  --epochs 16 --bsz 96 --save my_model.pt
```

### **Generate Paper Figures**
```bash
cd utils
python gen_fig_ablation.py
python make_icassp_tables.py
```

---

## ğŸ“ File Categories

### **Production Code** (`final/`)
- âœ… Best trained models
- âœ… Clean train/valid/test splits
- âœ… Main training & evaluation scripts
- âœ… Inference API

### **Utilities** (`utils/`)
- ğŸ”§ Dataset generation & augmentation
- ğŸ“Š Evaluation scripts (OOD, HRTF robustness)
- ğŸ“ˆ Figure & table generation
- ğŸ” Analysis tools

### **Documentation** (`docs/`)
- ğŸ“Š All evaluation metrics (JSON, CSV)
- ğŸ–¼ï¸ Paper figures (ready for generation)
- ğŸ“ Summary reports

### **Archive** (`archive/`)
- ğŸ—„ï¸ Old training scripts (v1-v6)
- ğŸ—„ï¸ Intermediate checkpoints
- ğŸ—„ï¸ Dataset variants
- âš ï¸ **Not for production use**

---

## âš ï¸ Important Notes

### **Main Paper Model**
```
final/models/t2sa_e2e_minilm_stage4f_lastmilefocus.pt
```
This achieved **33.2Â° angular error** in the ICASSP 2026 paper.

### **Dataset Split**
- Train: 1,092 samples
- Valid: 136 samples
- Test: 138 samples
- **Total (after augmentation):** ~17,000 samples

### **Nothing Was Deleted**
All files were **moved** to organized folders:
- Critical â†’ `final/`
- Helpers â†’ `utils/`
- Results â†’ `docs/`
- Historical â†’ `archive/`

---

## ğŸš€ Next Steps for GitHub

### 1. **Create `.gitignore`**
```gitignore
# Large files (use Git LFS)
*.pt
!final/models/*.pt

# Cache
cache/

# Archives
archive/

# Renderer outputs
renderer/demo_out_*
renderer/mos_questions_*

# Python
__pycache__/
*.pyc
.venv/
.ipynb_checkpoints/

# IDE
.vscode/
.idea/
```

### 2. **Create `requirements.txt`**
```txt
torch>=2.0.0
transformers>=4.30.0
librosa>=0.10.0
soundfile>=0.12.0
pydub>=0.25.0
numpy>=1.24.0
scipy>=1.10.0
tqdm>=4.65.0
```

### 3. **Add LICENSE**
Choose:
- MIT License (permissive)
- Apache 2.0 (patent protection)
- CC BY-NC 4.0 (academic use only)

### 4. **Host Models Externally**
Options:
- Hugging Face Hub (recommended)
- Zenodo (for reproducibility)
- Google Drive (quick setup)

Update README with download links.

### 5. **Create Demo Notebook**
`demo.ipynb` with:
- Installation instructions
- Inference walkthrough
- Audio rendering examples
- Visualization of predictions

---

## ğŸ“§ Maintainers

- **Seungryeol Paik** (paiiek@snu.ac.kr)
- **Kyogu Lee** (kglee@snu.ac.kr)

Seoul National University, AI Institute

---

## âœ… Cleanup Checklist

- [x] All scripts categorized (final vs archive)
- [x] Best models in `final/models/`
- [x] Clean datasets in `final/datasets/`
- [x] Utilities organized by function
- [x] Results moved to `docs/results/`
- [x] Cache files in dedicated folder
- [x] README.md comprehensive
- [x] No critical files deleted
- [x] Root directory clean (4 files only)
- [x] Ready for GitHub release

---

**Status:** âœ¨ Repository is clean and organized!
